---
title: "Topic 13: Inference for Categorical Data (Lab)"
engine: knitr
format: 
  live-html:
    webr:
      packages:
        - ggplot2
        - dplyr
        - gradethis
        - statsr
      cell-options: 
        persist: true
    live:
      show-solutions: false
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}
{{< include ./_extensions/r-wasm/live/_gradethis.qmd >}}

```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
#library(tidyverse)
library(ggplot2)
library(dplyr)
#library(learnr)
library(gradethis)
library(statsr)

#tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)

load("www/atheism.RData")
rm(inference)

#knitr::opts_chunk$set(eval = FALSE)
```

In August of 2012, news outlets ranging from the [Washington Post](http://www.washingtonpost.com/national/on-faith/poll-shows-atheism-on-the-rise-in-the-us/2012/08/13/90020fd6-e57d-11e1-9739-eef99c5fb285_story.html){target="_blank"} to the [Huffington Post](http://www.huffingtonpost.com/2012/08/14/atheism-rise-religiosity-decline-in-america_n_1777031.html){target="_blank"} ran a story about the rise of atheism in America. The source for the story was a poll that asked people, "Irrespective of whether you attend a place of worship or not, would you say you are a religious person, not a religious person or a convinced atheist?" This type of question, which asks people to classify themselves in one way or another, is common in polling and generates categorical data. In this workbook we take a look at the atheism survey and explore what's at play when making inference about population proportions using categorical data.

:::{.callout-note}
## Licensing Note

This is a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0){target="_blank"}. The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.
:::

## The survey

You can find the press-release for the WIN-Gallup International poll on the Global Index of Religion and Atheism [here](www/Religiosity_and_Atheism.pdf){target=_"blank"}. Please take a moment to review the report then address the following questions.

```{webr}
#| edit: false
#| output: false
#| define:
#|   - ok_response
library(htmltools)
ok_response <- function(response, n) {
  if (is.na(response)) HTML("")
  else if (response == n) div(HTML("Correct ✓"), style = "color: green")
  else div(HTML("Incorrect ✗"), style = "color: red")
}
```

```{webr}
#| edit: false
#| output: false
#| define:
#|   - ok_checkbox
ok_checkbox <- function(response, n) {
  if (is.na(response)) HTML("")
  else if (identical(paste(sort(response), collapse = ", "), paste(sort(n), collapse = ", "))) div(HTML("Correct ✓"), style = "color: green")
  else div(HTML("Incorrect ✗"), style = "color: red")
}
```

:::{.callout-caution}
## Question 1
In the first paragraph, several key findings are reported. Do these percentages appear to be *sample statistics* (derived from the data sample) or *population parameters*?

```{ojs}
//| echo: false
mutable ok_response = (response, n) => { return html`Loading...` };
viewof q1 = Inputs.radio(
  new Map([
    ["A mix of both", 1],
    ["Population Parameters", 2],
    ["Sample Statistics", 3]
  ])
);
ok_response(q1, 3);
```

:::

:::{.callout-caution}
## Question 2
The title of the report is Global Index of Religiosity and Atheism. To generalize the report’s findings to the global human population, what must we assume about the sampling method?

```{ojs}
//| echo: false
viewof q2 = Inputs.radio(
  new Map([
  ["The sample should include people of all religions, so samples should be taken near a diverse set of places of worship", 1],
  ["The sample must contain at least 10% of the global population", 2],
  ["The survey should be done on the phone to make sure that respondents understand the question being asked", 3],
  ["The sample must be random and representative of the global community", 4]
  ])
);
ok_response(q2, 4);
```

:::

:::{.callout-caution}
## Question 3
Do you expect that the required assumption was satisfied? What are the implications of this?

```{ojs}
//| echo: false
viewof q3 = Inputs.radio(
  new Map([
    ["No. In order to apply results to the global community the pollsters would need to conduct a census.", 1],
    ["Yes. Win-Gallup is a reputable polling organization.", 2],
    ["Yes. The study included a very large number of respondents.", 3],
    ["No. The study results can only be extended to countries and regions for which the sample data is representative.", 4]
  ])
);
ok_response(q3, 4);
```

:::

Turn your attention to Table 6 (pages 14 and 15) in the Religiosity and Atheism poll documentation, which reports the sample size and response percentages for all 57 countries. While this is a useful format to summarize the data, we will base our analysis on the original data set of individual responses to the survey. These original responses are loaded into this workbook for you in a data frame named `atheism`.

```{webr}
#| exercise: calculator-cell-1

```

:::{.callout-caution}
## Question 4
What does each row of `Table 6` correspond to? What does each row of the `atheism` data frame correspond to?

```{ojs}
//| echo: false
viewof q4 = Inputs.radio(
  new Map([
    ["Each row of `Table 6` contains the summarized responses by country while each row of `atheism` contains the response of an individual respondent.", 1],
    ["Each row of `Table 6` contains the response of an individual respondent while each row of `atheism` contains the summarized responses by country.", 2],
    ["Each row of both `Table 6` and the `atheism` data frame contain the response of an individual respondent.", 3],
    ["Each row of both `Table 6` and the `atheism` data frame contain the summarized responses by country.", 4]
])
);
ok_response(q4, 1)
```

:::

To investigate the link between these two ways of organizing this data, take a look at the estimated proportion of atheists in the United States. Towards the bottom of Table 6, we see that this is 5%. We should be able to come to the same number using the `atheism` data.

Run the command in the code block below and be sure to understand what the code is doing since you'll be asked to do some similar things later in the workbook. In that code cell, we create a new dataframe called `us12` that contains only the rows in `atheism` associated with respondents to the 2012 survey from the United States. Next, we calculate the proportion of atheist responses. Does it agree with the percentage in Table 6? If not, why?

```{webr}
#| exercise: us-atheism

us12 <- atheism %>%
  filter(nationality == "United States", 
         year == 2012)

us12 %>%
  count(response) %>%
  mutate(relative_frequency = n / sum(n))
```

## Inference on proportions

As you noted previously, Table 6 provides *statistics*, that is, calculations made from the sample of 51,927 people. We'd like insight into the population *parameters* instead. You answer the question, "What proportion of people *in your sample* reported being atheists?" with a sample statistic; while the question "What proportion of people *on Earth* would report being atheists?" is answered with an estimate of the parameter.

You'll use what you've learned about inferential tools for estimating population proportions in the previous workbook to answer questions related to the WIN-Gallup poll. Additionally, you'll explore how the value of the population proportion can impact the margin of error for a confidence interval.

As long as the conditions for inference are reasonably well satisfied, we can either calculate the standard error and construct the confidence interval by hand or allow the `inference()` function from the `{statsr}` package to do it for us. We note that the `inference()` function is part of the `{statsr}` package for R, which has been installed and loaded for you here.

Run the following code block to construct a confidence interval for the proportion of atheists in the US in 2012.

```{webr}
#| exercise: us-atheism-ci
#| setup: true

us12 <- atheism %>%
  filter(nationality == "United States", 
         year == 2012)
```

```{webr}
#| exercise: us-atheism-ci

inference(y = response,
          data = us12,
          statistic = "proportion", 
          type = "ci", 
          method = "theoretical", 
          success = "atheist")
```

Let's pause for a moment to go through the arguments of this function. The first argument is `y`, which is the response variable that we are interested in: `response`. The next argument, `data` tells the function which data frame to look in and find the `response` column. The `statistic` argument, is the parameter we're interested in: `"proportion"` (other options are `"mean"`, or `"median"`.) Next we decide on the `type` of inference we want: a hypothesis test (`"ht"`) or a confidence interval (`"ci"`). When performing a hypothesis test, we also need to supply the `null` value and `alternative` hypothesis but we're building a confidence interval here so we omit those values -- we can optionally set the `conf_level` parameter but the default is a 95% confidence interval (`conf_level = 0.95`). The `method` parameter chooses the method of inference: `"theoretical"` or `"simulation"` based -- our course is using a theoretical framework, so we will always use that option. Finally, since the goal is to construct an interval estimate for a proportion, it's necessary to specify which level constitutes a "success"; here that is a response of `"atheist"`.

Although formal confidence intervals and hypothesis tests don't show up in the WINN-Gallup report, suggestions of inference appear at the bottom of page 6: "In general, the error margin for surveys of this kind is $\pm$ 3-5% at 95% confidence". We will check the validity of this claim later on.

Use the code block below to help you answer the question that follows.

```{webr}
#| exercise: calculator-cell-2

```

::: { .hint exercise="calculator-cell-2"}
::: { .callout-note collapse="false"}
## Hint 1

The margin of error is half the width of the confidence interval. You might think of this as the "radius" of the confidence interval.

:::
:::

:::{.callout-caution}
## Question 5
Based on the R output, what is the margin of error for the estimate of the proportion of the proportion of atheists in US in 2012?

```{ojs}
//| echo: false

viewof q5 = Inputs.radio(
  new Map([
    ["0.0069", 1],
    ["0.0364", 2],
    ["0.0135", 3],
    ["0.0634", 4],
    ["0.0499", 5]
  ])
);

ok_response(q5, 3);
```

:::

Using the code block below and your `inference()` function, calculate confidence intervals for the proportion of atheists in 2012 in two other countries of your choice, and report the associated margins of error. Be sure to note whether the conditions for inference are met. It will be helpful to create new data sets for each of the two countries first, and then use these data sets in the `inference()` function to construct the confidence intervals.

```{webr}
#| exercise: use-inference

```

::: { .hint exercise="use-inference"}
::: { .callout-note collapse="false"}
## Hint 1

Revisit the code cell from earlier where we created the `us12` data frame

:::
:::

::: { .hint exercise="use-inference"}
::: { .callout-note collapse="false"}
## Hint 2

Use similar code to obtain data from a different country, year, or both!

:::
:::

::: { .hint exercise="use-inference"}
::: { .callout-note collapse="false"}
## Hint 3

Use `inference()` to build a confidence interval for the proportion of atheists in your new data frame.

:::
:::

## How does the proportion affect the margin of error?

Imagine you've set out to survey 1000 people on two questions: are you female? and are you left-handed? Since both of these sample proportions were calculated from the same sample size, they should have the same margin of error, right? Not so fast! While the margin of error does change with sample size, it is also affected by the proportion.

Think back to the formula for the standard error: $SE = \sqrt{p(1-p)/n}$. This is then used in the formula for the margin of error for a 95% confidence interval: $ME = 1.96\times SE = 1.96\times\sqrt{p(1-p)/n}$. Since the population proportion $p$ is in this $ME$ formula, it should make sense that the margin of error is in some way dependent on the population proportion. We can visualize this relationship by creating a plot of $ME$ vs. $p$, which is exactly what you'll do through these next few activities.

The code block below is pre-populated with the code necessary to make a vector `p` that is a sequence from 0 to 1 with each number separated by 0.01. The code then creates a vector of the margin of error (`me`) associated with each of these values of `p` using the familiar approximate formula ($ME = 2 \times SE$) -- note that we could also use the critical values associated with any confidence level we would like instead of 2 -- you might try this and see what happens! Lastly, we plot the two vectors against each other to reveal their relationship.

```{webr}
#| exercise: me-plot

n <- 1000
p <- seq(0, 1, 0.01)
me <- 2 * sqrt(p * (1 - p)/n)

ggplot() + 
  geom_point(aes(x = p, y = me)) + 
  labs(
    title = "Margin of Error and Population Proportion", 
    y = "Margin of Error", 
    x = "Population Proportion"
    )
```

:::{.callout-caution}
## Question 6
Describe the relationship between the population proportion, $p$, and margin of error.

```{ojs}
//| echo: false
viewof q6 = Inputs.radio(
  new Map([
    ["The margin of error is smaller for larger values of the population proportion.", 1],
    ["The margin of error is small if the population proportion is near 0 or 1 but is largest for values near 0.5", 2],
    ["The margin of error is larger for larger values of the population proportion.", 3],
    ["There is no meaningful relationship between the population proportion and margin of error.", 4]
  ])
);
ok_response(q6, 2);
```

:::

:::{.callout-caution}
## Question 7
Which of the following are implications of your answer above?

```{ojs}
//| echo: false
mutable ok_checkbox = (response, n) => { return html`Loading...` };
viewof q7 = Inputs.radio(
  new Map([
    ["In order to estimate a population proportion to within a desired margin of error, larger sample sizes will be needed if the true population proportion is near 0.5.", 1],
    ["Margins of error, and therefore confidence intervals, will be widest when the population proportion to be captured is close to 0.5", 2],
    ["Both are true", 3]
  ])
);
ok_response(q7, 3);
```

:::

We now know that both sample size and the population parameter impact the margin of error. Often times pollsters will have requirements for the margin of error for an estimate (for example, we may be interested in estimating a President's net favorability rating to within plus or minus three percentage points). They can use these requirements, prior information, and any intuition they may have about an approximate value of the population proportion to estimate how much data they need to collect in order to satisfy their requirements on the margin of error. We can estimate required sample size using the formula below, which is just a rearrangement of the formula for margin of error ($M_E$):
$$n \geq \left(\frac{Z_{\alpha/2}}{M_E}\right)^2\cdot p\left(1 - p\right)$$
In the formula above:

+ $Z_{\alpha/2}$ is the critical value associated with the desired confidence level
+ $M_E$ is the desired margin of error
+ $p$ is an estimate for the population proportion made by using any intuition the pollster has -- if there is no viable intuition then we use $p=0.5$, a worst case scenario (as you identified earlier).

You won't use this formula right now, but you'll need it to answer one of the questions at the end of this workbook.

## Success-failure condition

The textbook emphasizes that you must always check conditions before making inference. For inference on proportions, the sample proportion can be assumed to be nearly normal if it is based upon a random sample of independent observations and if both $np \geq 10$ and $n(1 - p) \geq 10$. This rule of thumb is easy enough to follow, but it makes one wonder: what's so special about the number 10?

The short answer is: nothing. You could argue that we would be fine with 9 or that we really should be using 11. The "best" value for such a rule of thumb is, at least to some degree, arbitrary. However, when $np$ and $n(1-p)$ both reach 10 the sampling distribution is sufficiently normal to use confidence intervals and hypothesis tests that are based on that approximation.

We can investigate the interplay between $n$ and $p$ and the shape of the sampling distribution by using simulations. To start off, we simulate the process of drawing 5000 samples of size 1040 from a population with a true atheist proportion of 0.1. For each of the 5000 samples we compute $\hat{p}$ and then plot a histogram to visualize their distribution.

Use the code block below to carry out this experiment.

```{webr}
#| exercise: sim-np

p <- 0.1
n <- 1040
p_hats <- rep(0, 5000)

for(i in 1:5000){
  samp <- sample(c("atheist", "non_atheist"), 
                 n, 
                 replace = TRUE, 
                 prob = c(p, 1-p))
  
  p_hats[i] <- sum(samp == "atheist")/n
}

ggplot() + 
  geom_histogram(aes(x = p_hats)) + 
  labs(title = "p = 0.1, n = 1040", 
       x = "Estimates for p") + 
  xlim(c(0, 0.18))
```

These commands build up the sampling distribution of $\hat{p}$ using the familiar `for` loop. You can read the sampling procedure for the first line of code inside the `for` loop as, "take a sample of size $n$ with replacement from the choices of atheist and non-atheist with probabilities $p$ and $1 - p$,respectively." The second line in the loop says, "calculate the proportion of atheists in this sample and record this value." The loop allows us to repeat this process 5,000 times to build an approximation of the sampling distribution.

Use the code block below to repeat the simulation we just ran but with `n = 400` and `p = 0.1`. Be sure to plot your result and compare it to your original simulation. What impact did lowering the number of observations have?

```{webr}
#| exercise: p-dist-400-10

```

::: { .hint exercise="p-dist-400-10"}
::: { .callout-note collapse="false"}
## Hint 1

Start with the code to run the original simulation. Change the sample size (`n`) and the population proportion (`p`)

:::
:::

Now re-run the experiment again, but with `n = 1040` and `p = 0.02`. Again, think about the impact that a smaller population proportion has on the distribution of estimates for the population proportion.

```{webr}
#| exercise: p-dist-1040-02

```

::: { .hint exercise="p-dist-1040-02"}
::: { .callout-note collapse="false"}
## Hint 1

Again, start with the code to run the original simulation. Change the sample size (`n`) and the population proportion (`p`).

:::
:::

Re-run the experiment one last time, but with `n = 400` and `p = 0.02`. Compare each of your resulting distributions. How does this connect back to the assumptions for inference with categorical data?

```{webr}
#| exercise: p-dist-400-02

```

::: { .hint exercise="p-dist-400-02"}
::: { .callout-note collapse="false"}
## Hint 1

Same idea here. Update the sample size and the population proportion from the original simulation.

:::
:::

:::{.callout-caution}
## Question 8
If you refer to `Table 6` again in [the WIN-Gallup report](www/Religiosity_and_Atheism.pdf){target=_"blank"}, you’ll find that Australia has a sample proportion of 0.1 on a sample size of 1040, and that Ecuador has a sample proportion of 0.02 on 400 subjects. Let’s suppose for this exercise that these point estimates are actually the truth. Then given the shape of their respective sampling distributions, do you think it is sensible to proceed with inference and report margin of errors, as the reports does?

```{ojs}
//| echo: false

viewof q8 = Inputs.radio(
  new Map([
    ["The report should not proceed with inference on Ecuador since the success-failure condition is not satisfied. The report can safely proceed with inference on Australia though.", 1],
    ["The report can proceed with inference on all countries. Since there were over 50,000 responses, the success-failure condition is satisfied.", 2],
    ["The report should not proceed with inference on either Ecuador or Australia, since the success-failure condition may not be satisfied for either country.", 3]
  ])
);
ok_response(q8, 1)
```

:::

## On your own

The question of atheism was asked by WIN-Gallup International in a similar survey that was conducted in 2005. (We assume here that sample sizes have remained the same.) Table 4 on page 12 of the report summarizes survey results from 2005 and 2012 for 39 countries. Try answering the following questions on your own. The code blocks are necessary for answering some of the questions, but are not needed for all.

1. Answer the following two questions using the `inference()` function from `{statsr}`. As always, write out the hypotheses for any tests you conduct and outline the status of the conditions for inference.

  + Is there convincing evidence that Spain has seen a change in its atheism index between 2005 and 2012? *Hint:* Create new data sets for respondents from Spain in 2005 and 2012 (look back at how we created `us12` earlier in this workbook). Form confidence intervals for the true proportion of atheists in both years, and determine whether they overlap.
  + Is there convincing evidence that the United States has seen a change in its atheism index between 2005 and 2012?

```{webr}
#| exercise: on-your-own-1

```

::: { .hint exercise="on-your-own-1"}
::: { .callout-note collapse="false"}
## Hint 1

Start by defining `spain` to be a data frame containing only responses from *Spain*. You don't need to filter on the `year`, since 2005 and 2012 are the only years with observed responses.

:::
:::

::: { .hint exercise="on-your-own-1"}
::: { .callout-note collapse="false"}
## Hint 2

Use the `inference()` function as earlier, but pass the `year` variable to the optional `x` argument. This will create *groups* for `year`, and `inference()` will automatically build a confidence interval for the difference in proportions of atheists between 2005 and 2012. You can ignore the warning about converting to a factor (R is telling you that you asked it to create groups from numbers...2005 and 2012, but that's exactly what we wanted).

:::
:::

2. If in fact there has been no change in the atheism index in any of the countries listed in Table 4, in how many of those countries would you expect to detect a change (at a significance level of 0.05) simply by chance? *Hint:* Look in the textbook index under Type 1 error.

```{webr}
#| exercise: on-your-own-2

```

3. Suppose you're hired by the local government to estimate the proportion of residents that attend a religious service on a weekly basis. According to the guidelines, the estimate must have a margin of error no greater than 1% with 95% confidence. You have no idea what to expect for $p$. How many people would you have to sample to ensure that you are within the guidelines? *Hint:* Refer to your plot of the relationship between $p$ and margin of error. Do not use the data set to answer this question.

```{webr}
#| exercise: on-your-own-3

```

::: { .hint exercise="on-your-own-3"}
::: { .callout-note collapse="false"}
## Hint 1

Use the sample size formula for inference on population proportions. That formula is on [the *Standard Error Decision Tree*](https://agmath.github.io/SiteFiles/StdErrorDecisionTree.pdf){target="_blank"} and was also included within this activity.

:::
:::

::: { .hint exercise="on-your-own-3"}
::: { .callout-note collapse="false"}
## Hint 2

Since you have no idea what proportion of residents attend a religious service on a weekly basis, use $p = 0.5$ as a *worst-case* estimate. This value of the population proportion results in the largest possible estimated sample size requirements.

:::
:::

## Submit

Hash code generation is not currently supported for these Quarto-Live versions of the interactive notebooks.

## Summary

Good work. I hope that this workbook has helped make inferential techniques a bit more intuitive for you. In particular, I hope that you better understand the connection between the margin of error and a confidence interval as well as the dependence of standard error on sample size and population proportion.

:::{.callout-note}
## Licensing Note
This is lab a derivative of a product of OpenIntro that is released under a [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). The oiginal lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.
:::
